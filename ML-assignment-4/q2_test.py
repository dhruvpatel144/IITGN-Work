# -*- coding: utf-8 -*-
"""Q2_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-h6mR7sy_h7Yi1dKE4xCb8nKprgkVDj
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from linearRegression.linear_regression import LinearRegression
from metrics import *
import time

np.random.seed(45)

N = 90
P = 10
X = pd.DataFrame(np.random.randn(N, P))
y = pd.Series(np.random.randn(N))
print(X.shape)


tmae = 0
tmse = 0
print('For manual gradient, no penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='manual', penalty_type='unregularized')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',N,', RMSE: ', tmse/20)
print(' Batch size=',N,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For manual gradient, l2 penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='manual', penalty_type='l2')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',N,', RMSE: ', tmse/20)
print(' Batch size=',N,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For jax gradient, no penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='jax', penalty_type='unregularized')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',N,', RMSE: ', tmse/20)
print(' Batch size=',N,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For jax gradient, l1 penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='jax', penalty_type='l1')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',N,', RMSE: ', tmse/20)
print(' Batch size=',N,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For stochastic gradient and l2 penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=1, gradient_type='manual', penalty_type='l2')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',1,', RMSE: ', tmse/20)
print(' Batch size=',1,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For mini-batch gradient and l2 penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_gradient_descent(X, y, batch_size=10, gradient_type='manual', penalty_type='l2')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',10,', RMSE: ', tmse/20)
print(' Batch size=',10,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")

tmae = 0
tmse = 0
print('For SGD with momentum and l2 penalty')
t1 = time.time_ns()
for i in range(20):
    LR = LinearRegression(fit_intercept=True)
    LR.fit_SGD_with_momentum(X, y, penalty='l2')
    y_hat = LR.predict(X)
    tmse += rmse(y_hat, y)
    tmae += mae(y_hat, y)
t2 = time.time_ns()
print(' Batch size=',1,', RMSE: ', tmse/20)
print(' Batch size=',1,', MAE: ', tmae/20)
print(' Execution time (ms): ', (t2-t1)/20000000)
print("---------------------------")


# lrs = [0.01, 0.02, 0.03]
# alphas = [0.9, 1.0, 1.1]
# a = np.zeros((3, 3))
# mdict = {'man-np': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}, 
#             'man-l2': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}, 
#             'jax-np': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}, 
#             'jax-l1': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}, 
#             'sgd-l2': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}, 
#             'mib-l2': {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}}

# for i in range(3):
#     for j in range(3):

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='manual', penalty_type='unregularized', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['man-np']['mse'][i][j] = tmse/20
#         mdict['man-np']['mae'][i][j] = tmae/20
#         mdict['man-np']['time'][i][j] = (t2-t1)/20000000

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='manual', penalty_type='l2', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['man-l2']['mse'][i][j] = tmse/20
#         mdict['man-l2']['mae'][i][j] = tmae/20
#         mdict['man-l2']['time'][i][j] = (t2-t1)/20000000

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='jax', penalty_type='unregularized', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['jax-np']['mse'][i][j] = tmse/20
#         mdict['jax-np']['mae'][i][j] = tmae/20
#         mdict['jax-np']['time'][i][j] = (t2-t1)/20000000

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=N, gradient_type='jax', penalty_type='l1', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['jax-l1']['mse'][i][j] = tmse/20
#         mdict['jax-l1']['mae'][i][j] = tmae/20
#         mdict['jax-l1']['time'][i][j] = (t2-t1)/20000000

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=1, gradient_type='manual', penalty_type='l2', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['sgd-l2']['mae'][i][j] = tmae/20
#         mdict['sgd-l2']['mse'][i][j] = tmse/20
#         mdict['sgd-l2']['time'][i][j] = (t2-t1)/20000000

#         tmae = 0
#         tmse = 0
#         t1 = time.time_ns()
#         for _ in range(20):
#             LR = LinearRegression(fit_intercept=True)
#             LR.fit_gradient_descent(X, y, batch_size=10, gradient_type='manual', penalty_type='l2', lr = lrs[i], alpha=alphas[j])
#             y_hat = LR.predict(X)
#             tmse += rmse(y_hat, y)
#             tmae += mae(y_hat, y)
#         t2 = time.time_ns()
#         mdict['mib-l2']['mse'][i][j] = tmse/20
#         mdict['mib-l2']['mae'][i][j] = tmae/20
#         mdict['mib-l2']['time'][i][j] = (t2-t1)/20000000

# print(mdict)

# lrs = [0.01, 0.02, 0.03]
# alphas = [0.9, 1.0, 1.1]
# moms = [0.8, 0.9, 1.0]
# a = np.zeros((3, 3, 3))
# sgddict = {'mae': a.copy(), 'mse': a.copy(), 'time': a.copy()}

# for i in range(3):
#     for j in range(3):
#         for k in range(3):
#             tmae = 0
#             tmse = 0
#             t1 = time.time_ns()
#             for _ in range(20):
#                 LR = LinearRegression(fit_intercept=True)
#                 LR.fit_SGD_with_momentum(X, y, penalty='l2', lr=lrs[i], alpha=alphas[j], momentum=moms[k])
#                 y_hat = LR.predict(X)
#                 tmse += rmse(y_hat, y)
#                 tmae += mae(y_hat, y)
#             t2 = time.time_ns()
#             sgddict['mae'][i, j, k] = tmae/20
#             sgddict['mse'][i, j, k] = tmse/20
#             sgddict['time'][i, j, k] = (t2-t1)/20000000

# print(sgddict)